{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d228431",
   "metadata": {},
   "source": [
    "# POC - Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3355705c",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7938895e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7794cd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e76629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbfec9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViltProcessor, ViltForQuestionAnswering\n",
    "import requests\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0a3410",
   "metadata": {},
   "source": [
    "## Sentiment Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d64d270",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faa24342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9997795224189758}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"We are very happy to show you the ðŸ¤— Transformers library.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead84123",
   "metadata": {},
   "source": [
    "## Speech Recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6806f61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/wav2vec2-base-960h and revision 55bb623 (https://huggingface.co/facebook/wav2vec2-base-960h).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline(task=\"automatic-speech-recognition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90c6fe56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'I HAVE A DREAM BUT ONE DAY THIS NATION WILL RISE UP LIVE UP THE TRUE MEANING OF ITS TREES'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7255f71",
   "metadata": {},
   "source": [
    "## Image Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c19b2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_classifier = pipeline(model=\"google/vit-base-patch16-224\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01ab16da",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = image_classifier(\n",
    "    images=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
    ")\n",
    "\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4392b413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.4403, 'label': 'lynx, catamount'},\n",
       " {'score': 0.0343,\n",
       "  'label': 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor'},\n",
       " {'score': 0.0321, 'label': 'snow leopard, ounce, Panthera uncia'},\n",
       " {'score': 0.0235, 'label': 'Egyptian cat'},\n",
       " {'score': 0.023, 'label': 'tiger cat'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9659a026",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "385255f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd46eb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20b6b91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1999, 1037, 4920, 1999, 1996, 2598, 2045, 2973, 1037, 7570, 10322, 4183, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = \"In a hole in the ground there lived a hobbit.\"\n",
    "tokenizer(sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca33861",
   "metadata": {},
   "source": [
    "## Question Answer - NLP "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b585b0",
   "metadata": {},
   "source": [
    "https://huggingface.co/deepset/roberta-base-squad2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56730304",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"deepset/roberta-base-squad2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d86206d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "093d6e5895454146a815b53521345498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\DELL\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08ae1d18325d45e19580df2f1b0c55b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/496M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b3716c8db304268875f33edb0f197dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)okenizer_config.json:   0%|          | 0.00/79.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2ff350539c7473cb55a0928981fea3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb05731ad2e84f8fb681c5f72344fc6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89f4699dfb0a4371be58fd018582992e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bafff005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.21171464025974274,\n",
       " 'start': 59,\n",
       " 'end': 84,\n",
       " 'answer': 'gives freedom to the user'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QA_input = {\n",
    "    'question': 'Why is model conversion important?',\n",
    "    'context': 'The option to convert models between FARM and transformers gives freedom to the user and let people easily switch between frameworks.'\n",
    "}\n",
    "nlp(QA_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccf95c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) Load model & tokenizer\n",
    "# model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52d05d7",
   "metadata": {},
   "source": [
    "## GPT 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c485487b",
   "metadata": {},
   "source": [
    "https://huggingface.co/gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce2d0c8c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f43355d1b2f14d19844c1acc067d4784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3a10100ec99451ab61c731c83839eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c0d591673ad444581c64495d040a456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99e6a93009704c20a277c315a837d563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cccc498d7cd24c4f807c16ac141c9254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f977555bb71e40b88efc4e1c8343227e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = pipeline('text-generation', model='gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1036de48",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'India is great country but it has to be in the middle. He also mentioned in his speech that this is not a question of the national sovereignty and'},\n",
       " {'generated_text': 'India is great country but sometimes, India is bad and sometimes, the best is always the worst. India is also a nation of intolerance and there are'},\n",
       " {'generated_text': 'India is great country but it\\'s very bad, if you say that, well, we\\'re not like that, so why don\\'t you come?\"'},\n",
       " {'generated_text': \"India is great country but not one of the world's well developed, which, frankly, the people have been waiting to grow, they might not live\"},\n",
       " {'generated_text': 'India is great country but we have all to go in and try to show India is good and the other side is evil.\"\\n\\nThe president also'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed(42)\n",
    "generator(\"India is great country but\", max_length=30, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa69e8c",
   "metadata": {},
   "source": [
    "## Document Question Answering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f8dc13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline(model=\"impira/layoutlm-document-qa\", task=\"document-question-answering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43305f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.03532538190484047,\n",
       "  'answer': 'Ghulam Mustafa Khan',\n",
       "  'start': 180,\n",
       "  'end': 182}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(\"ssw.png\",\"List all notable people\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a54e52e",
   "metadata": {},
   "source": [
    "## Visual QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7159985a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c5ffa48c0c47638f48532c343bc861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/470M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cbd84a4e816419b955e3c2a7b66073a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)okenizer_config.json:   0%|          | 0.00/320 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06d0d0fbfd114243aef66ba3a3362348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10dabfb296b4a0a88b3ad6c9a73833f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44b5ca20093643d9a7e87b124fd3cf39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57aeb788792b4ca8aea1a1a4b2152d95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)rocessor_config.json:   0%|          | 0.00/251 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    }
   ],
   "source": [
    "modelVqa = pipeline(model=\"dandelin/vilt-b32-finetuned-vqa\", task=\"visual-question-answering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "44a0f3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://th.bing.com/th/id/OIP.sfgBr1qnwi4joiZT7Sk0IgHaJs?w=155&h=203&c=7&r=0&o=5&pid=1.7\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "text = \"Name of radio?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "413f11bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = ViltProcessor.from_pretrained(\"dandelin/vilt-b32-finetuned-vqa\")\n",
    "model = ViltForQuestionAnswering.from_pretrained(\"dandelin/vilt-b32-finetuned-vqa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0701b351",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = processor(image, text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "098d9cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer: 0\n"
     ]
    }
   ],
   "source": [
    "outputs = model(**encoding)\n",
    "logits = outputs.logits\n",
    "idx = logits.argmax(-1).item()\n",
    "print(\"Predicted answer:\", model.config.id2label[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baba8e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058c1811",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "5ae58900cfbb8c43ab3495913814b7cf26024f51651a94ce8bf64d6111688e8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
